%YAML 1.2
---
KaBS:
   HOME: /home/naranjja/Devel/KaBS

   OUTPUTS: results  # if the leading "/" is provided then the absolute path is taken, otherwise the relative path to HOME ([KaBS][HOME])  will be used       

   BATCH:
        # for the batch systems with a script defined, the submission command will be: <command> <parameters> <script>
        # if parameter is '<', it might be changed by 'cat <script> | <command>'
        - name: LSF
          script: run.lsf.in # if the leading "/" is provided then the absolute path is taken, otherwise the relative path to [KaBS][HOME]/etc  will be used          
          submit: 
                command: bsub 
                parameters:  < 
                submittedmsg: Job <%JOBID%> is submitted to queue 
          monitor: bjobs -u all | gawk '{print $1}' | grep %JOBID%
          numprocs: 4,8,16,32
          tasks_per_node: 8           
          queue: rh6_q20m                             
          launcher: mpirun.lsf  
          launcher_flags:    
          mpiflags: -a openmpi
          wallclock: 20       
                
        # for a  manual launcher the submission command will be: <command> <parameters> <exe> <args>
        # variables %XXX% specific to the dataset will be replaced at the moment the script is generated
        # Other %XXX% variables can be used in the 'submit' section if they are defined..ie: %hostslistfile% 
        - name: NONE
          hostslistfile: hostnames      
          submit: 
                command: mpirun 
                parameters: -np %NUMPROCS% -machinefile %HOSTSLISTFILE%  

   BENCH: 
      APPS:
         - name: cp2k
           active: false

         - name: gromacs
           active: false

         - name  : material_studio
           active: false     
 
         - name: namd
           active: true
           batch: LSF     
           # following parameters are dataset dependent... 
           # This values will be used unless they are redefined in the "dataset" section 
           exe: namd2_mpi                       
           modules: module load gcc mpi-openmpi  libs-extra fftw2/2.1.5-openmpi-1.4.3-sse4.2-sp namd    
           # here goes the specific dataset configuration
           dataset: 
              - name: namd_nucleosome146Katoms
                active: true
                args: nucleosome146Katoms.namd  > nucleosome.out  2>nucleosome.err
                analysis:  
                   outputs: 
                      output: nucleosome.out                      
                   metrics: 
                      - name: wallclock
                        units: secs
                        command: cat %OUTPUT% | grep WallClock | gawk '{print $2}' 
                   
                      - name: days/ns
                        units: days/ns
                        command: cat %OUTPUT% | grep  Benchmark | gawk 'END{print $8}' 

                      - name: cputime
                        units: secs
                        command: cat %OUTPUT% | grep CPUTime | gawk '{print $4}'   
                     
                      - name: memory
                        units: MB
                        command: cat %OUTPUT%  | grep Memory | gawk '{print $6}'
 
              - name: namd_apoa1  
                active: false
                args:  apoa1.namd   > apoa1.out 2>apoa1.err                        
                analysis:  
                   outputs: 
                      output: apoa1.out  
                      another_output: KaBS_%NAME%_%NUMPROCS%.out          
                   metrics: 
                      - name: wallclock
                        units: secs
                        command: cat %OUTPUT% | grep WallClock | gawk '{print $2}' 
                   
                      - name: days/ns
                        units: days/ns
                        command: cat %OUTPUT% | grep  Benchmark | gawk 'END{print $8}' 

                      - name: cputime
                        units: secs
                        command: cat %OUTPUT% | grep CPUTime | gawk '{print $4}'   
                     
                      - name: memory
                        units: MB
                        command: cat %OUTPUT%  | grep Memory | gawk '{print $6}'

         - name: vasp
           active: false
           batch: LSF
           exe: vasp         
           modules: module load gcc mpi-openmpi vasp
           dataset:
              - name: vasp_Hg
                active: true
                args: 
                analysis:  
                   outputs: 
                      outcar: OUTCAR
                      oszicar: OSZICAR
                      outcar_ref:  OUTCAR.ref
                      oszicar_ref: OSZICAR.ref
                   metrics: 
                      - name: wallclock
                        units: secs
                        command: $cat %OUTCAR% | grep "Elapsed time" | gawk '{print $4}' 
                  
         - name: siesta
           active: true
           batch: LSF
           exe: siesta
           modules: module load gcc mpi-openmpi blas blacs  lapack scalapack siesta
           dataset:
              - name: siesta_test
                active: true
                args: < fen.fdf  > output.txt
                analysis:  
                   outputs:
                      clock: CLOCK
                      output: output.txt
                      fenxml: fen.xml
                      feneig: fen.EIG
                   metrics: 
                      - name: wallclock
                        units: secs
                        command: cat %CLOCK% | grep "End of run" | gawk '{print $4}'
                      - name: AvgMem # Avg mem per node
                        units: MB
                        command: cat %OUTPUT% | grep "Node" | gawk '{print $10}' |  gawk 'BEGIN{sum=0 ; c=0}{ sum=sum+$1 ; c=c+1  }END{ print sum/c}'  
                      - name: FinalEnergy
                        units: eV
                        command:  cat %OUTPUT%  | grep "Total =" | gawk '{print $4}' 
                        


      FILESYSTEM: 
         - name: gpfs
           active: false

      MATHLIBS: 
         - name: blas
           active: false
     
         - name: lapack
           active: false     

      NETWORKS: 
         - name: mpi
           batch: LSF         
           active: true
           modules:  module load gcc mpi-openmpi    
           numprocs: 32              
           dataset:           
                - name: mpi_io_test # MPI-IO on Scratch N procs to 1 file
                  active: true
                  exe: ./fs_test.x
                  # 10 objects of 1GB to write by each proc 
                  args:  -type 2 -strided 1 -nobj 10 -size 1073741824  -target /scratch/mpiio_testfile -deletefile -touch 2 -check 2
                  analysis:
                        outputs:
                                output: KaBS_%NAME%_%NUMPROCS%.out 
                        metrics:
                                - name: ""
                                  units: ""
                                  command: ""

                - name: skampi-5.0.4-r0355
                  active: true
                  exe: ./skampi
                  dependencies: ski/skampi_coll.ski
                  args:  -i ski/skampi_coll.ski  -o skaoutf.txt
                  analysis:
                        outputs:
                                output: skaoutf.txt                                              
                        metrics:
                                - name: ""
                                  units: ""
                                  command: ""                      
                        
                - name: imb_3.2.3                            
                  active: true  
                  exe: bin/IMB-MPI1 # Full path or  Relative to the current dir
                  dependencies:   #comma separated list of  files that will be copied to the run directory ... always relative to the 'source' dir
                  args: 1>imb.output                     
                  analysis:
                        outputs: 
                                output: imb.output
                        metrics:
                                - name: pingpong_BW
                                  units: MB/secs
                                  command: cat %OUTPUT% | grep -A28 "Benchmarking PingPong" |  gawk '$1 ~ /[0-9]/'  | gawk 'BEGIN{sum=0}{if ($1>=32768) sum=sum+$4  }END{ print sum/8}'

                                - name: pingping_BW
                                  units: MB/secs
                                  command: cat %OUTPUT% | grep -A28 "Benchmarking PingPing" |  gawk '$1 ~ /[0-9]/'  | gawk 'BEGIN{sum=0}{if ($1>=32768) sum=sum+$4  }END{ print sum/8}'       

                                - name: sendrecv_BW
                                  units: MB/secs
                                  command: cat %OUTPUT% | grep -B10  "Benchmarking Exchange" | head | gawk 'BEGIN{sum=0}{if ($1>=32768) sum=sum+$6  }END{ print sum/8}'

                                - name: exchange_BW
                                  units: MB/secs
                                  command: cat %OUTPUT% | grep -B10  "Benchmarking Allreduce" | head | gawk 'BEGIN{sum=0}{if ($1>=32768) sum=sum+$6  }END{ print sum/8}'
 
                                - name: allreduce_avg_t
                                  units: usecs
                                  command: cat %OUTPUT% | grep -B10  "Benchmarking Reduce" | head | gawk 'BEGIN{sum=0}{if ($1>=32768) sum=sum+$5  }END{ print sum/8}'
 
                                - name: alltoall_avg_t
                                  units: usecs
                                  command: cat %OUTPUT% | grep -B10  "Benchmarking Bcast" | head | gawk 'BEGIN{sum=0}{if ($1>=32768) sum=sum+$5  }END{ print sum/8}'
 
                                - name: bcast_avg_t 
                                  units: usecs
                                  command: cat %OUTPUT% | grep -B10  "Benchmarking Barrier" | head | gawk 'BEGIN{sum=0}{if ($1>=32768) sum=sum+$5  }END{ print sum/8}'


      SYNTHETIC:
         - name: hpcc
           active: true
           batch: LSF         
           exe: hpcc 
           args: 
           modules: module load gcc atlas/3.8.4-sse3 mpi-openmpi   
           dependencies: hpccinf.txt
           numprocs: 128
           dataset:
                 - name: with_atlas
                   active: true
                   analysis:   
                        outputs:
                                hpccout: hpccoutf.txt
                        metrics:
                                - name: Procs
                                  units: ""
                                  command: cat  %HPCCOUT% | grep CommWorldProcs | gawk -F "=" '{print $2}'
                                - name: HPL
                                  units: TFlops
                                  command: cat  %HPCCOUT% | grep HPL_Tflops | gawk -F "=" '{print $2}'
                                - name: Single_DGEMM
                                  units: GFlops
                                  command: cat  %HPCCOUT% | grep  SingleDGEMM_Gflops| gawk -F "=" '{print $2}'
                                - name: Star_DGEMM
                                  units: GFlops
                                  command: cat  %HPCCOUT% | grep  StarDGEMM_Gflops| gawk -F "=" '{print $2}'
#                                - name: STREAM
#                                  units: GB/s
#                                  command: ""
                                - name: PTRANS
                                  units: GBs
                                  command:  cat  %HPCCOUT% | grep  PTRANS_GBs | gawk -F "=" '{print $2}'
                                - name: FFT
                                  units: GFlops
                                  command: cat  %HPCCOUT% | grep  MPIFFT_Gflops | gawk -F "=" '{print $2}'

      ACCEPTANCE: 
        active: false                        
...
